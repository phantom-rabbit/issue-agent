# graphs/issue_graph.py
from langgraph.graph import StateGraph, START, END
from core.issue_state import IssueState
from agents.classifier_agent import classify_node
from agents.retriever_agent import retriever_node
from agents.reply_agent import reply_node



def build_issue_graph():
    # åˆ›å»ºçŠ¶æ€å›¾ï¼Œå¹¶æŒ‡å®šçŠ¶æ€ç±»å‹
    graph = StateGraph(IssueState)

    graph.add_node("classifier", classify_node)
    graph.add_node("retriever", retriever_node)
    graph.add_node("reply", reply_node)



    graph.add_edge(START, "classifier")
    graph.add_conditional_edges("classifier", should_retrieve)
    graph.add_edge("retriever", "reply")
    graph.add_edge("reply", END)

    return graph.compile()


def should_retrieve(state: IssueState):
    """åˆ¤æ–­æ˜¯å¦è¿›å…¥retrieverèŠ‚ç‚¹"""
    return "retriever" if state.get("need_reply", False) else END


if __name__ == "__main__":
    # åˆå§‹åŒ–çŠ¶æ€
    state = IssueState(
        issue_body="CUDA out of memory when running model",
        issue_number=123,
        issue_title="CUDA out of memory",
        comments=[
            {"body": "Same issue as #122", "author": "user1"},
            {"body": "å¸®æˆ‘ç»§ç»­è§£å†³", "author": "user2"},
        ],
    )

    graph = build_issue_graph()

    result = graph.invoke(state)
    
    print("ğŸ§© Graph Result:", result)
